{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.misc as spm\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "numpy.random.seed(42)\n",
    "\n",
    "amount_crops = 30 # Quantos patches de cada imagem\n",
    "patch_size = 32 # Tamanho dos patches das amostras\n",
    "label_size = 20 # Tamanho dos patches das labels\n",
    "conv_side = 6 # será a borda da convolução?\n",
    "scale = 2\n",
    "# BORDER_CUT = 8\n",
    "BLOCK_STEP = 16\n",
    "BLOCK_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(x_path, y_path):\n",
    "    x_names = sorted(os.listdir(x_path))\n",
    "    y_names = sorted(os.listdir(y_path))\n",
    "    \n",
    "    x_count = len(x_names)\n",
    "    y_count = len(y_names)\n",
    "\n",
    "    data = numpy.zeros((nums * amount_crops, 1, patch_size, patch_size), dtype=numpy.uint8)\n",
    "    label = numpy.zeros((nums * amount_crops, 1, label_size, label_size), dtype=numpy.uint8)\n",
    "\n",
    "    for i in range(nums):\n",
    "        name = _path + names[i]\n",
    "        hr_img = mpimg.imread(name)\n",
    "        shape = hr_img.shape\n",
    "\n",
    "        hr_img = hr_img[:, :, 0]\n",
    "\n",
    "        # two resize operation to produce training data and labels\n",
    "        lr_img = spm.imresize(lr_img, size=shape, interp='bicubic')\n",
    "\n",
    "        # produce amount_crops random coordinate to crop training img\n",
    "        Points_x = numpy.random.randint(0, min(shape[0], shape[1]) - patch_size, amount_crops)\n",
    "        Points_y = numpy.random.randint(0, min(shape[0], shape[1]) - patch_size, amount_crops)\n",
    "\n",
    "        for j in range(amount_crops):\n",
    "            lr_patch = lr_img[Points_x[j]: Points_x[j] + patch_size, Points_y[j]: Points_y[j] + patch_size]\n",
    "            hr_patch = hr_img[Points_x[j]: Points_x[j] + patch_size, Points_y[j]: Points_y[j] + patch_size]\n",
    "\n",
    "            lr_patch = lr_patch.astype(float) / 255.\n",
    "            hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "            data[i * amount_crops + j, 0, :, :] = lr_patch\n",
    "            label[i * amount_crops + j, 0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "            \n",
    "            import matplotlib\n",
    "            matplotlib.use('TKagg')\n",
    "            \n",
    "            plt.imshow(lr_patch)\n",
    "            plt.waitforbuttonpress()\n",
    "            plt.imshow(hr_patch)\n",
    "            plt.waitforbuttonpress()\n",
    "\n",
    "            # cv2.imshow(\"lr\", lr_patch)\n",
    "            # cv2.imshow(\"hr\", hr_patch)\n",
    "            # cv2.waitKey(0)\n",
    "            %matplotlib inline\n",
    "    return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_crop_data(x_path, y_path):\n",
    "    x_names = sorted(os.listdir(x_path))\n",
    "    y_names = sorted(os.listdir(y_path))\n",
    "    \n",
    "    x_count = len(x_names)\n",
    "    y_count = len(y_names)\n",
    "\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    # We are using 8-bit deep 256x256 and 512x512 images for the \n",
    "    # subsampled and labels, respectively\n",
    "    for i in range(nums):\n",
    "        x_name = x_path + x_names[i]\n",
    "        y_name = y_path + y_names[i]\n",
    "        \n",
    "        subsampled_img = mpimg.imread(x_name)\n",
    "        label_img = mpimg.imread(y_name)\n",
    "        \n",
    "        shape = label_img.shape\n",
    "\n",
    "        # just resizing to produce a bicubic interpolated image, since the image is already subsampled\n",
    "        subsampled_img = spm.imresize(subsampled_img, size=shape, interp='bicubic')\n",
    "\n",
    "        width_num = (shape[0] - (BLOCK_SIZE - BLOCK_STEP) * 2) / BLOCK_STEP\n",
    "        height_num = (shape[1] - (BLOCK_SIZE - BLOCK_STEP) * 2) / BLOCK_STEP\n",
    "        for k in range(width_num):\n",
    "            for j in range(height_num):\n",
    "                x = k * BLOCK_STEP\n",
    "                y = j * BLOCK_STEP\n",
    "                hr_patch = label_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "                lr_patch = subsampled_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "\n",
    "                lr_patch = lr_patch.astype(float) / 255.\n",
    "                hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "                lr = numpy.zeros((1, patch_size, patch_size), dtype=numpy.uint8)\n",
    "                hr = numpy.zeros((1, label_size, label_size), dtype=numpy.uint8)\n",
    "\n",
    "                lr[0, :, :] = lr_patch\n",
    "                hr[0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "\n",
    "                data.append(lr)\n",
    "                label.append(hr)\n",
    "\n",
    "    data = numpy.array(data, dtype=float)\n",
    "    label = numpy.array(label, dtype=float)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hdf5(data, labels, output_filename):\n",
    "    \"\"\"\n",
    "    This function is used to save image data and its label(s) to hdf5 file.\n",
    "    output_file.h5,contain data and label\n",
    "    \"\"\"\n",
    "\n",
    "    x = data.astype(numpy.uint8)\n",
    "    y = labels.astype(numpy.uint8)\n",
    "\n",
    "    with h5py.File(output_filename, 'w') as h:\n",
    "        h.create_dataset('data', data=x, shape=x.shape)\n",
    "        h.create_dataset('label', data=y, shape=y.shape)\n",
    "        # h.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(file):\n",
    "    with h5py.File(file, 'r') as hf:\n",
    "        data = numpy.array(hf.get('data'))\n",
    "        label = numpy.array(hf.get('label'))\n",
    "        train_data = numpy.transpose(data, (0, 2, 3, 1))\n",
    "        train_label = numpy.transpose(label, (0, 2, 3, 1))\n",
    "        return train_data, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = prepare_crop_data(DATA_PATH)\n",
    "write_hdf5(data, label, \"crop_train.h5\")\n",
    "# data, label = prepare_data(TEST_PATH)\n",
    "# write_hdf5(data, label, \"test.h5\")\n",
    "# _, _a = read_training_data(\"train.h5\")\n",
    "# _, _a = read_training_data(\"test.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
