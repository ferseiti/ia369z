{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc as spm\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "numpy.random.seed(42)\n",
    "\n",
    "amount_crops = 30 # Quantos patches de cada imagem\n",
    "patch_size = 64 # Tamanho dos patches das amostras\n",
    "label_size = 52 # Tamanho dos patches das labels\n",
    "conv_side = 6 # será a borda da convolução?\n",
    "scale = 2\n",
    "# BORDER_CUT = 8\n",
    "BLOCK_STEP = 32\n",
    "BLOCK_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(x_file, y_file):\n",
    "    data = numpy.array((5,5))\n",
    "    label = numpy.array((5,5))\n",
    "    with h5py.File(x_file, 'r') as hfx:\n",
    "        data = numpy.array(hfx['data'])\n",
    "    with h5py.File(y_file, 'r') as hfy:\n",
    "        label = numpy.array(hfy['data'])\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(x_path, y_path):\n",
    "\n",
    "    full_data, full_label = load_data(x_path, y_path)\n",
    "\n",
    "    fd_shape = full_data.shape\n",
    "    fl_shape = full_label.shape\n",
    "\n",
    "    nums = full_data.shape[0]\n",
    "    data = numpy.zeros((nums * amount_crops, 1, patch_size, patch_size), dtype=numpy.uint8)\n",
    "    label = numpy.zeros((nums * amount_crops, 1, label_size, label_size), dtype=numpy.uint8)\n",
    "\n",
    "    for i in range(full_data.shape[0]):\n",
    "        \n",
    "        lr_img = full_data[i, :, :]\n",
    "        hr_img = full_label[i, :, :]\n",
    "\n",
    "        shape = hr_img.shape\n",
    "\n",
    "        lr_img = spm.imresize(lr_img, size=shape, interp='bicubic')\n",
    "\n",
    "        # produce amount_crops random coordinate to crop training img\n",
    "        Points_x = numpy.random.randint(0, min(shape[0], shape[1]) - patch_size, amount_crops)\n",
    "        Points_y = numpy.random.randint(0, min(shape[0], shape[1]) - patch_size, amount_crops)\n",
    "\n",
    "        for j in range(amount_crops):\n",
    "            lr_patch = lr_img[Points_x[j]: Points_x[j] + patch_size, Points_y[j]: Points_y[j] + patch_size]\n",
    "            hr_patch = hr_img[Points_x[j]: Points_x[j] + patch_size, Points_y[j]: Points_y[j] + patch_size]\n",
    "\n",
    "            lr_patch = lr_patch\n",
    "            hr_patch = hr_patch\n",
    "\n",
    "            data[i * amount_crops + j, 0, :, :] = lr_patch\n",
    "            label[i * amount_crops + j, 0, :, :] = hr_patch\n",
    "\n",
    "    return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_crop_data(x_path, y_path):\n",
    "    \n",
    "    full_data, full_label = load_data(x_path, y_path)\n",
    "\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    # We are using 8-bit deep 256x256 and 512x512 images for the \n",
    "    # subsampled and labels, respectively\n",
    "\n",
    "    for i in range(full_data.shape[0]):\n",
    "        \n",
    "        subsampled_img = full_data[i, :, :]\n",
    "        label_img = full_label[i, :, :]\n",
    "        \n",
    "        shape = label_img.shape\n",
    "\n",
    "        # just resizing to produce a bicubic interpolated image, since the image is already subsampled\n",
    "        subsampled_img = spm.imresize(subsampled_img, size=shape, interp='bicubic')\n",
    "\n",
    "        width_num = (shape[0] - (BLOCK_SIZE - BLOCK_STEP) * 2) // BLOCK_STEP\n",
    "        height_num = (shape[1] - (BLOCK_SIZE - BLOCK_STEP) * 2) // BLOCK_STEP\n",
    "        for k in range(width_num):\n",
    "            for j in range(height_num):\n",
    "                x = k * BLOCK_STEP\n",
    "                y = j * BLOCK_STEP\n",
    "                hr_patch = label_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "                lr_patch = subsampled_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "        \n",
    "                lr = numpy.zeros((1, patch_size, patch_size), dtype=numpy.uint8)\n",
    "                hr = numpy.zeros((1, label_size, label_size), dtype=numpy.uint8)\n",
    "                \n",
    "                lr[0, :, :] = lr_patch\n",
    "#                 hr[0, :, :] = hr_patch                \n",
    "                hr[0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "\n",
    "                data.append(lr)\n",
    "                label.append(hr)\n",
    "\n",
    "    data = numpy.array(data, dtype=float)\n",
    "    label = numpy.array(label, dtype=float)\n",
    "    \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hdf5(data, labels, output_filename):\n",
    "    \"\"\"\n",
    "    This function is used to save image data and its label(s) to hdf5 file.\n",
    "    output_file.h5,contain data and label\n",
    "    \"\"\"\n",
    "\n",
    "    x = data.astype(numpy.uint8)\n",
    "    y = labels.astype(numpy.uint8)\n",
    "\n",
    "    with h5py.File(output_filename, 'w') as h:\n",
    "        h.create_dataset('data', data=x, shape=x.shape)\n",
    "        h.create_dataset('label', data=y, shape=y.shape)\n",
    "        # h.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(file):\n",
    "    with h5py.File(file, 'r') as hf:\n",
    "        data = numpy.array(hf.get('data'))\n",
    "        label = numpy.array(hf.get('label'))\n",
    "        train_data = numpy.transpose(data, (0, 2, 3, 1))\n",
    "        train_label = numpy.transpose(label, (0, 2, 3, 1))\n",
    "        return train_data, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100352, 1, 64, 64) (100352, 1, 52, 52)\n"
     ]
    }
   ],
   "source": [
    "data, label = prepare_crop_data('../data/sub_data/sub_data_pick.h5', '../data/ground_data/ground_data_pick.h5')\n",
    "\n",
    "print(data.shape, label.shape)\n",
    "\n",
    "# write_hdf5(data, label, \"64crop_train.h5\")\n",
    "\n",
    "use_thorn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_thorn:\n",
    "    data2, label2 = prepare_crop_data('../sub_data/sub_data_thorn.h5', 'ground_data/ground_data_thorn.h5')\n",
    "    print(data2.shape, label2.shape)\n",
    "    print(data.shape[0] + data2.shape[0])\n",
    "    data3 = numpy.empty((data.shape[0] + data2.shape[0], 1, 64, 64))\n",
    "    label3 = numpy.empty((label.shape[0] + label2.shape[0], 1, 64, 64))\n",
    "else:\n",
    "    data3 = numpy.empty_like(data)\n",
    "    label3 = numpy.empty_like(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_thorn:\n",
    "    data3[:data.shape[0],:,:,:] = data\n",
    "    label3[:label.shape[0],:,:,:] = label\n",
    "else:\n",
    "    try:\n",
    "        data3[data.shape[0]:,:,:,:] = data2\n",
    "        label3[label.shape[0]:,:,:,:] = label2\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100352, 1, 64, 64) (100352, 1, 52, 52)\n"
     ]
    }
   ],
   "source": [
    "write_hdf5(data3, label3, \"crop_train.h5\")\n",
    "\n",
    "print(data3.shape, label3.shape)\n",
    "\n",
    "del(data)\n",
    "del(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
